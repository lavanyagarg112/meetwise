So does the SEC, meaning secure and govern growth and data science, meaning applied ML, mlops and anti abuse team meeting. That's a big mouthful. We might get a better name over time. And that's our meeting for September 14 or 15th in APAC. And I hi Alan. Glad you're here. Why are you here when it's midnight? We could talk. Glad you're here. Don't make it a habit to come to this meeting since it's really late for you, so. But I'm glad. Thanks for coming at least once. So, news and events. I've got a lot of things on the agenda today because of some of this, so apologies for that, but I think it's going to go down over time based on feedback. I'm going to work to do more summarized communications to improve the signal to noise ratio in my communications to groups of people, including this group of people. This was wrote in for this group, adding more items to our staff meeting agenda, often as real only rather than posting to our slack channel. And I am going to be assuming that people leaders on the team will attend this meeting or read the notes and not rely on the Slack channel. So keep that in mind. Let's see. B is a read only item, unless anybody wants to discuss it and see Phil has hi and welcome Alan, to the meeting. I've asked Alan to step in as acting full stack manager for security policies while I hire an EM. Alan has graciously accepted this wonderful opportunity. So welcome Alan. Thank you. I've got the next item as well. So anti abuse is moving product sections from SEC to data science. Data science is effectively a rename of the model Ops section. So data science will include two stages. The existing model ops, which has three groups in it, which Mun can talk more about, and the anti abuse stage, which only currently has one group, which is called anti abuse. I think at some point there are plans to split anti abuse into two groups, but that's not in the near term and we're working through all the changes around that. There's lots of workday changes, lots of handbook changes. Mon, did you want to say anything more about data science or model ops? No, I think for us we just roll up to data science, everything else stays the same. We still have the two main groups applied ML mlops and then later data ops as part of it. Yeah. So in e thanks, Thomas, for continuing to compile and report on across all of my teams that I'm responsible for in the engineering allocation meeting on error budgets and reliability and security incidents. So really do appreciate that. Gotta give Neil a high five, too. He does have. He does half of these now. And apologies for the noise if I keep asking for. What's the story behind what's going on with reliability or secure or error budget stuff? Just trying to provide air cover. And I apologize, Neil. I totally forgot you took half of these since Thomas has been doing it for so long. But appreciate it, Neil. I know you volunteered for it and we discussed it and I just forgot. Kind of a thankless role, honestly. And I volunteered because of the exposure I get from it. It's nice to be part of a different collective group of people. I was going to mention, I'll type this in here, but Tiago had set up for container security a bot that weekly. I think it's Mondays or like Sunday. We'll ping the team and ask for volunteer to go and resource that data. And we just enabled it for threat insights. It's actually pretty sweet. And it just does all the work for you, Thomas. Right. We don't have to ping people ourselves. So I'll put a note in there for that. F is read only. And Bill, you've got g. Yeah. Talent assessment. So we had an update from Juliana. The dates haven't been confirmed yet, but it'll be sometime from mid October through till December. I think e group sign off is expected to be mid December before everyone goes on holiday. They've got a draft timeline in there, but the dates aren't in the handbook yet. The big change is we're moving to do it in workday. That's not available yet. I haven't seen a demo of it. I don't know what questions will be asked, but there's an optional self evaluation which will move into workday, and then the work that we do as managers will also happen in workday. At the moment, some people are using the Google Doc, which is listed on the talent assessment page for self evaluations and for the manager work. I'd suggest continuing to use those docs until we get access to workday and see what the exact differences are. Hi, andj. Or read only unless anybody wants to discuss them. And, Thomas, you got item k. Yeah. Apologies for the late, like, live addition to the agenda on this one. But one more note on a change. We're rolling out with insecure, pretty lightweight, and that we're establishing a second team within dynamic analysis. And so, issue is there for folks want to play that would like to follow along or ask any questions about it for the plan for right now is I'm going to be serving as a team tactic. And in addition to normally scheduled SEM duties, for lack of a better way of putting it. And so happy to answer any questions that folks have about that. I had a quick question. We've done the same thing in threat insights with Neil and Thiago each having teams. What are you going to call your new team? Or how will you differentiate? Was not planning to differentiate it. It's just a second team. Within dynamic analysis. We're not creating a new group. Which I think is the same pattern that's happening within threat insights as well. It's just two teams. No, I know that. There's Tangerine and there's navy. I'm not a tangerine person myself, so we'll have to figure it out. Yeah. I don't know if there's another t color, Thomas. I struggled with that one. That's the theme. Tomato. I don't know. We'll figure it out. We'll figure it out. We'll figure it out. The differentiation. I think the difference between what's happening in threat insights and within dynamic analysis is that this is a split or long feature category. Even though we're keeping that, we're not putting a new group. The distinction is along. Like who's working on specific feature categories themselves. So where the fracture point is happening is a little different. But the. But the approach and effect are the same. I hope so. On to big rocks and hot issues section. I don't know if it's a big rock, but kind of belong to perhaps more now places. So did that survey where we got an awesome response rate from the team on how to improve the mister rate for the team. Then I took a really long time to go through all the results and summarize and make initial recommendations. So lost a little bit of momentum. I got caught up in other things like cross functional prioritization and the customer escalation. So since then, this is actually used by John Hope to lead a discussion at the development offsite last week on just improving engineering. Velocity is one of the things he used to power it, so it had value there. But I've seen no comments, I think, from anybody in this group, which means either no time, forgot about it or it doesn't. We looked at it and it doesn't have much value. And any of those things are okay. I'm just curious where the group landed and if you haven't taken a look yet to see if there's anything you want to take away from it on things you might want to consider asking you to do so and to consider. Not to do, but to consider. Anybody got a chance to read it yet and think about it, or not just yet. My guess is perhaps everybody's really busy and they haven't looked yet. I mean, at a high level. Jay, Neil Thiago, we've talked about changes. I think, Jay, you've already looked at some changes around refinement. That was an area that you were going to look at for anti abuse and report back by the end of the quarter Thiago and Neil, I can't remember what we ended up with for three insights. Yeah, I'm hoping that mister rate is kind of an artifact or a byproduct of some other actions. The big thing we're doing is more whole type of work, like random, miscellaneous, not scheduled, not PM, necessarily actions or issues. And that actually is creating some more additional work. Like, it's just like free time work. I want to change of pace, move to something else momentarily. And these are generally smaller types of issues, too, so they're quicker to knock out. Therefore they create more Mrs. Which has been a cool byproduct. So I think that's helping us succeed there. Yeah, we're also seeing some success with, we've implemented like a weekly refinement meeting, kind of check in, make sure that stories are broken down tiny enough. I think with smaller bits of work, we're seeing a higher Mr. Rate. Um, it's debatable whether or not that's like, just inflated, right? Like, you can work on a small piece of code and ship it, and you can do that. A lot of times you're going to get a higher Mr. Rate. We're trying to be reasonable with that. Um, I am noticing a nice tick up, uh, after implementing the refinement meeting, so let's hope for the best. One note on good. Sorry, I was going to say one note on refinement in stack analysis, we're experimenting with the new section in our planning feature just called looking forward. And in there, we're using that as like a baseline where we add issues that we think need refinement that will most likely be worked on in the next one to three milestones. So we're using that as kind of a base cover for some engineer to go in and add their issues and make sure they get refined within this milestone. Not necessarily any implementation, but just refinement itself. I should stop talking on mute. Thank you. Omar Thomas, you want to verbalize your comment? Yeah, I'll verbalize and then I'll say more and then I'll finish writing what I was going to put down underneath it in just a moment. So this was an agenda item with the EMS, and I can say it now in the secure stage since that is the analyzer teams now. So this was a topic yesterday. So I would assume that this is more like had a chance to read but not digest the content and what I was about to write. And I am cautious in saying this because it almost comes across as smug. And that is not my intent in that. Looking at the mister rate within SEC compared to company wide, historically it runs two to three misters per engineer per month higher. And I think a good bit of that has to do with the, I mean, we've taken this to be true, or at least asserted it to be true, in that it's smaller teams that are working closely together in less busy projects than we see within the rails platform itself, which does have an impact. That's not to say that we cannot do better, but the comparison, the favorable comparison, at least to me, and I will admit this at times will lessen the urgency on this particular topic. And I have to admit that bias that I have. Thanks, Thomas. Thanks everyone. So I didn't see any comments on the issue, but that's totally fine. People found some of it useful, some of the analysis useful, and that's great. So I will close the issue accordingly and just link to these notes. Good stuff, Thomas, you've got item B. Okay. All right. After this then. All right. Fedramp and the can't or won't fix security issues that we may be having. So we've got them for security issues that are subject to FeDRamp. If we, if you have a feature category that is fips compliant or certified, you're probably going to be part of the FeDramp evaluation. And any security issue that has a CVE associated with it, which means dependency or container scanning specifically has to have a remediation plan, even if they're false positives. And so that's led to a separate discussion on what do we need to do for, do we need to do anything related to security findings on the commercial versions of analyzer specifically? That was the catalyst for this particular conversation, because on container scanning we get a lot of findings related to debian based images that that project has not shipped a fix for or won't fix ship of fix for. So there is a separate thread that is going on here about what to do and can we do deviation requests in bulk for this class? For this class of findings? The TLDR is below, and there's a couple of options that are being brainstormed within this particular thread. So I wanted, and I know I've said a lot of words and I didn't say it well, but I wanted to bring it here in case there was any questions or commentary. Nothing directly related to what you've just talked about, but sort of related for Fedramp, you're looking at any FIPS related security issues that have been raised. How far are you going in terms of auditing to find anything that hasn't already been identified? There is. I'll link in another issue, a separate issue that is, that has instructions from Appsec on what they would like us to do as far as setting up container scanning. And they have set up a project with a single configuration that they're asking us to use. There is some debate as to, as to how that project has been configured because it uses a combination of three container scanning tools rather than one. And so they've asked us to use that as a baseline for the FIPS images specifically, since they're UBI or the UBI specific images. They're, they're equivalent in my mind, even though they're, they're different meanings. So, TLDR, talk to Apsec. Got it. Nikhil. Nikhil George is our stable counterpart, if folks don't know, at least in sec. Um, and so he's been quite responsive in keen, and he is also helping chase down answers when, when he doesn't have them. So that's a big, he's been, he's been a big help thus far. Yeah, so in, thanks for bringing this up, Thomas. So in the hallway, so from the development staff meeting, I copied and pasted the notes in there, but net is the TLDR is can folks, the request to me and my peers was can folks check with their teams to see if the approvals are affecting them? So this is the new approval rules on segregation of duties. So ask this group, not that everybody's here, but in the group, and they shouldn't be because all meetings are optional. But has this had an impact, these new approval rules? Anecdotally, I've seen a few cases where team members have realized that they need to get an additional approval, but I'm not aware that it's actually slowing things down. Okay, no news is good news on this, probably, unless we're missing, unless it's happening and we're not noticing it where it is slowing things down. But just keep an eye on it in case it does. Everyone, please so, good stuff. So, with recent changes, we've done a couple of different changes with secure and govern broken out from secure and a data ops team. And this and that is, I just compared the name of my team with my peers. My peers have one word team names, ops dev, create, et cetera. Mine is sec growth and data science, which is pretty wordy and also makes. When I go into dashboards, I have to pull data from multiple places across my teams. So I was thinking about a one word name. I've started to get feedback on it. Naming things is really important at GitLab to name the right kinds of things and give them good names. So I'm going to run it by David DeSanto tomorrow, as he's a great person to bounce such things off of. I landed on enrichment because what we do makes other things better. We enrich them. It's kind of a very broad term, but it does cover what we do. Not sure we're going to change the name, which I'm not sure it's going to affect anyone but me. That's actually my intent, is it only affects my stuff, not everyone else's, or at least everyone else's in a small way, or others in a small way, but we'll see. Any thoughts on this? Good idea, bad idea? I'm not wed to this. I'm looking for feedback. Yeah. Obviously the other examples relate to either sections or stages, whereas enrichment doesn't. So you'd be introducing something new here. This affects me as well. I have a subset of enrichment, so it would be kind of enrichment light. I'm not sure. I'm not sure. I think you and I have spoken about this. I'm not sure we would get approval to introduce a new name or department level. We'd certainly have to talk to people ops about introducing that in workday. Okay, so a couple of things. You know, these kinds of things I would sometimes put in slack and I'm trying to avoid a number of distinct slack messages. So putting it in here, making a lot read only when possible. So I've got c, though, which is not read only. So I would like to add announcements of work, anniversaries and new hires to the meeting template. PM does this. I attended the PM staff meeting. I was a guest speaker there this week. And like the camaraderie we have. Good camaraderie. The camaraderie there was pretty good. You know, Fern, who's shadowing me today, I think he sat in on the PM meeting as well. It was a pretty good feel. Of just people really knowing each other well and getting along well. So those are just two things I took away from. It is anniversaries and new hires. I'll verbalize Thiago's comment. Great idea for new hires. Don't care much about work anniversaries. We already have a bot for that. What I'd say is I always seem to miss the bot announcements as they cover the whole company versus a bot just announcing for our team. If no interest in that part, I'm happy to exclude. Neil, you like the idea of adding. Yeah. You don't? I mean, just last week, I think it was Phil celebrated his third year, and I congratulated him. But then I missed another team member in SEc, you know? Cause there's like, 20 people on that list. Plus it's team member updates. That's not a channel I look at a lot, like, weekly. I just happen to see that the day of. So I do like being able to celebrate together in this group. Maybe also thanks or praise section, like, thanks for doing this. Great job on that. To remind ourselves to do that. As engineers, we tend to focus on the problems and challenges and not the celebrating the wins. Are you suggesting that we add new content into this document for that? Or that we just link to the slack announcements that we've already made? I think it's nice to verbalize them. So maybe link to the slack announcements, but also verbalize, which. I know it sounds like a bunch of busy work. I don't want to do things twice. Maybe we add the sections and people use them as they see fit, whatever that happens to be. But please don't over. Don't create busy work for yourself either. So, judgment call by each person. Thomas, it looks like you had a Thomas and Mon. You had some thoughts on this, too. Yeah, I like it. We don't celebrate enough. We don't do enough for team cohesion, team celebration across the board. And just as a corollary to thing that I haven't communicated well, I was hoping to add this kind of thing to our monthly section. Wide retrospectives, new hires, discretionary bonuses, work anniversaries, big feature releases. I mean, anything that we want to announce and celebrate, we ought to make sure that it's. I don't want to say shout to the rooftops, but worship to the heavens, but. But we. They're big deals, and we don't make. And. And we undersell, in my opinion. Yeah. Oh, sorry. And, hey, Fernando here. So I'm shadowing Wayne now just to introduce myself from the technical marketing team. And I'm. I'll send the document right now, which is something that we do for our kind of get together, team meetings. And it kind of shows. You can look through it. I shared it to everyone on the Zoom chat, but you can see that we provide updates, the new team members, and small little introductions, and you can see sections that we have on gratitude and actual spotlights that we show, like who we're actually praising, what they've done. That's good. And how we can highlight that, because that will motivate employees, kind of really increase that morale, because what we're seeing is these employees are actually getting recognized for good work that they've done and they're getting shoutouts because a lot of times, at least in our team, the cases we don't really, although we work with each other, we sometimes are kind of siloed, busy working on different things. So it's good to know what everyone's working on and what everyone's doing. Somewhat related to what you were just speaking on, but just thought I'd share that. Thanks, Fernando, indeed. So I'm not going to read all of this from Daniel Croft, but summarizing, he is looking for feedback on the development, vision and mission and direction. We're brainstorming in the development department on mission and Vision in particular. The approach is we want everybody open up a little spreadsheet and follow the instructions. Anybody interested? So if you're interested in doing so, should take about ten to 15 minutes. Please do it in the next week. Good stuff. There something we covered also, the development off site that Daniel took as an action item to follow up on. Thomas, you've got e. Yep. All right. Because I cannot remember. And so I'm hoping to crowdsource a little bit of configuration archaeology, so to speak. Is there a reason that we don't use reviewer roulette? If folks can remember, the reason I'm asking is contained within that thread, but that is a tool that actually is being used to track if we have enough maintainers on any given project. And since we don't use it, we're showing up. And so that's why I was. That's why I'm asking. Yeah. When you say reviewer roulette, are you talking about on the individual analyzers? Yeah. Speaking only for Dash, we haven't had a need for it because we have six engineers. That's just going to rule out the same six people. Yeah. Roll a six sided diet. That's what I think it is. But it's from a larger, like, if the company, like where do we need more maintainers? Is the question that the organization is asking. I mean, I'd suggest they're looking in the wrong place. If they're looking in roulette to see, to find out the number of maintainers, that's the wrong place. The engineering projects page should list all the maintainers. If you set up your team YAML entries correctly, I would have thought that was more the single source of truth. Apparently not. So, yeah, yeah, I'm looking at the chart. I mean, I think on some of these projects, we just haven't filled it out. I'll give you, like, we have the API, the cub fuzz, we have one engineer that works on it. So we haven't gone and added a maintainer there because they know who they are. So if we are trying to maintain that as a single source of truth, we need to just go through and scrub it. Sorry, Seth. I'm reminded of this man. I'm reminded of the Spider man meme with the two spider men pointing at each other. Who's the reviewer? Who's the author? It's the same person. It's been a long day, so I'm a little punchy, but yes, that makes sense. So, Seth, are you saying you haven't added it to individual team members YAML files in the handbook yet? Right. I believe for that one, there's just no entry for it. I mean, we could. I think if you do, that should do it. Yeah, well, it should. They shouldn't be using just roulette. They should be using that as a source of truth. And I think if you've listed maintainers, that should cover it. A follow up question would be, does that cover the senior plus engineers? Must be a maintainer requirement or nothing. Thomas, you buried the lead the way. What do you call buried the lead? I took the read only off your comment there so you can announce it. Well, we're going to end with the best news of the day. That's all. But the maintainer requirement. Yes, it does, because it's required for senior plus. Going back to that is just maintaining one or more, I think, is the requirement. If I remember correctly, I was talking about the Olivier news. Yeah, I know. I was just making sure we were finished with the topic above. All right. And we're at time, so I will move on and take that as a prompt. Yeah. Olivier has popped back on slack to announce that the newest addition to their family is here and happened over the weekend. So big congrats to his family. For that. And we'll be hoping to celebrate him later when he does, when he. When he returns to work. Google. Thanks, everybody. Have a great day.